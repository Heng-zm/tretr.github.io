<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Camera Subject Detection with Tracking</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
            text-align: center;
        }
        video, canvas {
            border: 1px solid black;
            margin-bottom: 20px;
        }
    </style>
</head>
<body>
    <h1>Camera Subject Detection with Tracking</h1>
    <video id="video" width="640" height="480" autoplay></video>
    <canvas id="canvas" width="640" height="480"></canvas>
    <div id="result"></div>

    <script>
        // Load the object detection model
        let model;
        cocoSsd.load().then(loadedModel => {
            model = loadedModel;
            console.log("Model loaded successfully");
        });

        // Access the webcam
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const context = canvas.getContext('2d');

        // Track previous detections to simulate basic tracking
        let previousDetections = [];

        // Set up the webcam stream
        async function setupWebcam() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: true
                });
                video.srcObject = stream;
            } catch (err) {
                console.error('Error accessing webcam: ', err);
            }
        }

        // Function to calculate the intersection over union (IoU) for object tracking
        function getIoU(box1, box2) {
            const x1 = Math.max(box1[0], box2[0]);
            const y1 = Math.max(box1[1], box2[1]);
            const x2 = Math.min(box1[0] + box1[2], box2[0] + box2[2]);
            const y2 = Math.min(box1[1] + box1[3], box2[1] + box2[3]);
            const areaIntersection = Math.max(0, x2 - x1) * Math.max(0, y2 - y1);
            const areaBox1 = box1[2] * box1[3];
            const areaBox2 = box2[2] * box2[3];
            const areaUnion = areaBox1 + areaBox2 - areaIntersection;
            return areaIntersection / areaUnion;
        }

        // Detect objects and update canvas with bounding boxes and tracking
        async function detectObjects() {
            if (!model) {
                console.log('Waiting for model...');
                return;
            }

            // Ensure the video is playing and has dimensions
            if (video.readyState === 4 && video.videoWidth > 0 && video.videoHeight > 0) {
                model.detect(video).then(predictions => {
                    // Clear the canvas before drawing new predictions
                    context.clearRect(0, 0, canvas.width, canvas.height);

                    // List of current detections (we'll match these with previous detections for tracking)
                    const currentDetections = [];

                    predictions.forEach(prediction => {
                        // Draw bounding box
                        context.beginPath();
                        context.rect(
                            prediction.bbox[0],
                            prediction.bbox[1],
                            prediction.bbox[2],
                            prediction.bbox[3]
                        );
                        context.lineWidth = 3;
                        context.strokeStyle = "green";
                        context.fillStyle = "green";
                        context.stroke();
                        context.fillText(
                            `${prediction.class} (${Math.round(prediction.score * 100)}%)`,
                            prediction.bbox[0],
                            prediction.bbox[1] > 10 ? prediction.bbox[1] - 5 : 10
                        );

                        // Add detection to current list for tracking
                        currentDetections.push(prediction);
                    });

                    // Track the objects by matching current detections with previous detections
                    if (previousDetections.length > 0) {
                        // Match the boxes using IoU (Intersection over Union)
                        currentDetections.forEach(current => {
                            let matched = false;
                            previousDetections.forEach(prev => {
                                const iou = getIoU(prev.bbox, current.bbox);
                                if (iou > 0.5) { // Threshold for matching detections
                                    matched = true;
                                    // Draw previous bounding box with a different color
                                    context.beginPath();
                                    context.rect(
                                        prev.bbox[0],
                                        prev.bbox[1],
                                        prev.bbox[2],
                                        prev.bbox[3]
                                    );
                                    context.lineWidth = 3;
                                    context.strokeStyle = "blue"; // Blue for tracked boxes
                                    context.stroke();
                                }
                            });
                            // If not matched, it's a new object; track with a new color
                            if (!matched) {
                                context.beginPath();
                                context.rect(
                                    current.bbox[0],
                                    current.bbox[1],
                                    current.bbox[2],
                                    current.bbox[3]
                                );
                                context.lineWidth = 3;
                                context.strokeStyle = "orange"; // Red for new objects
                                context.stroke();
                            }
                        });
                    }

                    // Update the previous detections for next frame
                    previousDetections = currentDetections;

                    // Re-run detection every frame
                    requestAnimationFrame(detectObjects);
                }).catch(err => {
                    console.error('Error detecting objects: ', err);
                });
            } else {
                // If the video is not yet ready, try again after a short delay
                requestAnimationFrame(detectObjects);
            }
        }

        // Initialize the webcam and start detection
        async function init() {
            await setupWebcam();

            // Wait until the video has started playing and has valid dimensions
            video.onplay = function () {
                console.log("Video started playing");
                detectObjects(); // Start detecting and tracking objects
            };
        }

        init();
    </script>
</body>
</html>
